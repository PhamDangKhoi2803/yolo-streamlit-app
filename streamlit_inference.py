# Ultralytics üöÄ AGPL-3.0 License - https://ultralytics.com/license

import io
from typing import Any

import cv2
import numpy as np
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase
import av

from ultralytics import YOLO
from ultralytics.utils import LOGGER
from ultralytics.utils.checks import check_requirements
from ultralytics.utils.downloads import GITHUB_ASSETS_STEMS


class VideoProcessor(VideoProcessorBase):
    """L·ªõp x·ª≠ l√Ω video cho streamlit-webrtc ƒë·ªÉ x·ª≠ l√Ω khung h√¨nh webcam."""
    def __init__(self):
        self.model = None
        self.conf = 0.25
        self.iou = 0.45
        self.selected_ind = []
        self.enable_trk = "No"

    def set_model(self, model, conf, iou, selected_ind, enable_trk):
        self.model = model
        self.conf = conf
        self.iou = iou
        self.selected_ind = selected_ind
        self.enable_trk = enable_trk

    def recv(self, frame):
        img = frame.to_ndarray(format="bgr24")  # Chuy·ªÉn frame sang ƒë·ªãnh d·∫°ng BGR cho OpenCV
        if self.model:
            if self.enable_trk == "Yes":
                results = self.model.track(
                    img, conf=self.conf, iou=self.iou, classes=self.selected_ind, persist=True
                )
            else:
                results = self.model(img, conf=self.conf, iou=self.iou, classes=self.selected_ind)
            annotated_frame = results[0].plot()
            return av.VideoFrame.from_ndarray(annotated_frame, format="bgr24")
        return frame


class Inference:
    """
    L·ªõp ƒë·ªÉ th·ª±c hi·ªán suy lu·∫≠n ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng, ph√¢n lo·∫°i h√¨nh ·∫£nh, ph√¢n ƒëo·∫°n h√¨nh ·∫£nh v√† ∆∞·ªõc l∆∞·ª£ng t∆∞ th·∫ø.

    L·ªõp n√†y cung c·∫•p c√°c ch·ª©c nƒÉng ƒë·ªÉ t·∫£i m√¥ h√¨nh, c·∫•u h√¨nh c√†i ƒë·∫∑t, t·∫£i l√™n t·ªáp video v√† th·ª±c hi·ªán suy lu·∫≠n
    th·ªùi gian th·ª±c b·∫±ng Streamlit v√† c√°c m√¥ h√¨nh Ultralytics YOLO.

    Thu·ªôc t√≠nh:
        st (module): Module Streamlit ƒë·ªÉ t·∫°o giao di·ªán ng∆∞·ªùi d√πng.
        temp_dict (dict): T·ª´ ƒëi·ªÉn t·∫°m th·ªùi ƒë·ªÉ l∆∞u ƒë∆∞·ªùng d·∫´n m√¥ h√¨nh v√† c√°c c·∫•u h√¨nh kh√°c.
        model_path (str): ƒê∆∞·ªùng d·∫´n ƒë·∫øn m√¥ h√¨nh ƒë√£ t·∫£i.
        model (YOLO): Th·ªÉ hi·ªán c·ªßa m√¥ h√¨nh YOLO.
        source (str): Ngu·ªìn video ƒë∆∞·ª£c ch·ªçn (webcam ho·∫∑c t·ªáp video).
        enable_trk (str): T√πy ch·ªçn b·∫≠t theo d√µi ("C√≥" ho·∫∑c "Kh√¥ng").
        conf (float): Ng∆∞·ª°ng ƒë·ªô tin c·∫≠y cho ph√°t hi·ªán.
        iou (float): Ng∆∞·ª°ng IoU cho non-maximum suppression.
        org_frame (Any): V√πng ch·ª©a cho khung h√¨nh g·ªëc ƒë∆∞·ª£c hi·ªÉn th·ªã.
        ann_frame (Any): V√πng ch·ª©a cho khung h√¨nh ƒë√£ ch√∫ th√≠ch ƒë∆∞·ª£c hi·ªÉn th·ªã.
        vid_file_name (str | int): T√™n t·ªáp video ƒë√£ t·∫£i l√™n ho·∫∑c ch·ªâ s·ªë webcam.
        selected_ind (List[int]): Danh s√°ch c√°c ch·ªâ s·ªë l·ªõp ƒë∆∞·ª£c ch·ªçn ƒë·ªÉ ph√°t hi·ªán.
    """

    def __init__(self, **kwargs: Any):
        """
        Kh·ªüi t·∫°o l·ªõp Inference, ki·ªÉm tra y√™u c·∫ßu Streamlit v√† thi·∫øt l·∫≠p ƒë∆∞·ªùng d·∫´n m√¥ h√¨nh.

        Args:
            **kwargs (Any): C√°c ƒë·ªëi s·ªë t·ª´ kh√≥a b·ªï sung cho c·∫•u h√¨nh m√¥ h√¨nh.
        """
        check_requirements("streamlit>=1.29.0")  # Ki·ªÉm tra y√™u c·∫ßu Streamlit
        import streamlit as st

        self.st = st  # Tham chi·∫øu ƒë·∫øn module Streamlit
        self.source = None  # L·ª±a ch·ªçn ngu·ªìn video (webcam ho·∫∑c t·ªáp video)
        self.enable_trk = False  # C·ªù ƒë·ªÉ b·∫≠t/t·∫Øt theo d√µi ƒë·ªëi t∆∞·ª£ng
        self.conf = 0.25  # Ng∆∞·ª°ng ƒë·ªô tin c·∫≠y cho ph√°t hi·ªán
        self.iou = 0.45  # Ng∆∞·ª°ng IoU cho non-maximum suppression
        self.org_frame = None  # V√πng ch·ª©a cho khung h√¨nh g·ªëc
        self.ann_frame = None  # V√πng ch·ª©a cho khung h√¨nh ch√∫ th√≠ch
        self.vid_file_name = None  # T√™n t·ªáp video ho·∫∑c ch·ªâ s·ªë webcam
        self.selected_ind = []  # Danh s√°ch ch·ªâ s·ªë l·ªõp ƒë∆∞·ª£c ch·ªçn
        self.model = None  # Th·ªÉ hi·ªán m√¥ h√¨nh YOLO

        self.temp_dict = {"model": None, **kwargs}
        self.model_path = None  # ƒê∆∞·ªùng d·∫´n t·ªáp m√¥ h√¨nh
        if self.temp_dict["model"] is not None:
            self.model_path = self.temp_dict["model"]

        LOGGER.info(f"Ultralytics Solutions: ‚úÖ {self.temp_dict}")

    def web_ui(self):
        """Thi·∫øt l·∫≠p giao di·ªán web Streamlit v·ªõi c√°c y·∫øu t·ªë HTML t√πy ch·ªânh."""
        menu_style_cfg = """<style>MainMenu {visibility: hidden;}</style>"""  # ·∫®n menu ch√≠nh

        # Ti√™u ƒë·ªÅ ch√≠nh c·ªßa ·ª©ng d·ª•ng Streamlit
        main_title_cfg = """<div><h1 style="color:#FF64DA; text-align:center; font-size:40px; margin-top:-50px;
        font-family: 'Archivo', sans-serif; margin-bottom:20px;">·ª®ng d·ª•ng Streamlit Ultralytics YOLO</h1></div>"""

        # Ph·ª• ƒë·ªÅ c·ªßa ·ª©ng d·ª•ng Streamlit
        sub_title_cfg = """<div><h4 style="color:#042AFF; text-align:center; font-family: 'Archivo', sans-serif; 
        margin-top:-15px; margin-bottom:50px;">Tr·∫£i nghi·ªám ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng th·ªùi gian th·ª±c tr√™n webcam v·ªõi s·ª©c m·∫°nh 
        c·ªßa Ultralytics YOLO! üöÄ</h4></div>"""

        # Thi·∫øt l·∫≠p c·∫•u h√¨nh trang HTML v√† th√™m HTML t√πy ch·ªânh
        self.st.set_page_config(page_title="·ª®ng d·ª•ng Streamlit Ultralytics", layout="wide")
        self.st.markdown(menu_style_cfg, unsafe_allow_html=True)
        self.st.markdown(main_title_cfg, unsafe_allow_html=True)
        self.st.markdown(sub_title_cfg, unsafe_allow_html=True)

    def sidebar(self):
        """C·∫•u h√¨nh thanh b√™n Streamlit cho c√°c c√†i ƒë·∫∑t m√¥ h√¨nh v√† suy lu·∫≠n."""
        with self.st.sidebar:  # Th√™m logo Ultralytics
            logo = "https://raw.githubusercontent.com/ultralytics/assets/main/logo/Ultralytics_Logotype_Original.svg"
            self.st.image(logo, width=250)

        self.st.sidebar.title("C·∫•u h√¨nh ng∆∞·ªùi d√πng")  # Th√™m c√°c y·∫øu t·ªë v√†o menu c√†i ƒë·∫∑t d·ªçc
        self.source = self.st.sidebar.selectbox(
            "Ngu·ªìn video",
            ("webcam", "video"),
        )  # Th√™m dropdown ch·ªçn ngu·ªìn
        self.enable_trk = self.st.sidebar.radio("B·∫≠t theo d√µi", ("C√≥", "Kh√¥ng"))  # B·∫≠t theo d√µi ƒë·ªëi t∆∞·ª£ng
        self.conf = float(
            self.st.sidebar.slider("Ng∆∞·ª°ng ƒë·ªô tin c·∫≠y", 0.0, 1.0, self.conf, 0.01)
        )  # Thanh tr∆∞·ª£t cho ƒë·ªô tin c·∫≠y
        self.iou = float(self.st.sidebar.slider("Ng∆∞·ª°ng IoU", 0.0, 1.0, self.iou, 0.01))  # Thanh tr∆∞·ª£t cho ng∆∞·ª°ng NMS

        col1, col2 = self.st.columns(2)  # T·∫°o hai c·ªôt ƒë·ªÉ hi·ªÉn th·ªã khung h√¨nh
        self.org_frame = col1.empty()  # V√πng ch·ª©a cho khung h√¨nh g·ªëc
        self.ann_frame = col2.empty()  # V√πng ch·ª©a cho khung h√¨nh ch√∫ th√≠ch

    def source_upload(self):
        """X·ª≠ l√Ω t·∫£i l√™n t·ªáp video ho·∫∑c ch·ªçn webcam qua giao di·ªán Streamlit."""
        self.vid_file_name = ""
        if self.source == "video":
            vid_file = self.st.sidebar.file_uploader("T·∫£i l√™n t·ªáp video", type=["mp4", "mov", "avi", "mkv"])
            if vid_file is not None:
                g = io.BytesIO(vid_file.read())  # ƒê·ªëi t∆∞·ª£ng BytesIO
                with open("ultralytics.mp4", "wb") as out:  # M·ªü t·ªáp t·∫°m d∆∞·ªõi d·∫°ng bytes
                    out.write(g.read())  # ƒê·ªçc bytes v√†o t·ªáp
                self.vid_file_name = "ultralytics.mp4"
        elif self.source == "webcam":
            self.vid_file_name = "webrtc"  # ƒê√°nh d·∫•u ngu·ªìn l√† webcam qua webrtc

    def configure(self):
        """C·∫•u h√¨nh m√¥ h√¨nh v√† t·∫£i c√°c l·ªõp ƒë∆∞·ª£c ch·ªçn ƒë·ªÉ suy lu·∫≠n."""
        # Th√™m menu dropdown ƒë·ªÉ ch·ªçn m√¥ h√¨nh
        available_models = [x.replace("yolo", "YOLO") for x in GITHUB_ASSETS_STEMS if x.startswith("yolo11")]
        if self.model_path:  # N·∫øu ng∆∞·ªùi d√πng cung c·∫•p m√¥ h√¨nh t√πy ch·ªânh, th√™m m√¥ h√¨nh v√†o danh s√°ch
            available_models.insert(0, self.model_path.split(".pt")[0])
        selected_model = self.st.sidebar.selectbox("M√¥ h√¨nh", available_models)

        with self.st.spinner("ƒêang t·∫£i m√¥ h√¨nh..."):
            self.model = YOLO(f"{selected_model.lower()}.pt")  # T·∫£i m√¥ h√¨nh YOLO
            class_names = list(self.model.names.values())  # Chuy·ªÉn t·ª´ ƒëi·ªÉn th√†nh danh s√°ch t√™n l·ªõp
        self.st.success("T·∫£i m√¥ h√¨nh th√†nh c√¥ng!")

        # H·ªôp ch·ªçn nhi·ªÅu l·ªõp v·ªõi t√™n l·ªõp v√† l·∫•y ch·ªâ s·ªë c·ªßa c√°c l·ªõp ƒë∆∞·ª£c ch·ªçn
        selected_classes = self.st.sidebar.multiselect("L·ªõp", class_names, default=class_names[:3])
        self.selected_ind = [class_names.index(option) for option in selected_classes]

        if not isinstance(self.selected_ind, list):  # ƒê·∫£m b·∫£o selected_ind l√† danh s√°ch
            self.selected_ind = list(self.selected_ind)

    def inference(self):
        """Th·ª±c hi·ªán suy lu·∫≠n ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng th·ªùi gian th·ª±c tr√™n video ho·∫∑c webcam."""
        self.web_ui()  # Kh·ªüi t·∫°o giao di·ªán web
        self.sidebar()  # T·∫°o thanh b√™n
        self.source_upload()  # T·∫£i l√™n ngu·ªìn video
        self.configure()  # C·∫•u h√¨nh ·ª©ng d·ª•ng

        if self.st.sidebar.button("B·∫Øt ƒë·∫ßu"):
            stop_button = self.st.button("D·ª´ng")
            if self.vid_file_name == "webrtc":
                # S·ª≠ d·ª•ng streamlit-webrtc cho webcam
                webrtc_ctx = webrtc_streamer(
                    key="example",
                    video_processor_factory=VideoProcessor,
                    rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
                    media_stream_constraints={"video": True, "audio": False},
                )
                if webrtc_ctx.video_processor:
                    webrtc_ctx.video_processor.set_model(
                        self.model, self.conf, self.iou, self.selected_ind, self.enable_trk
                    )
            else:
                # X·ª≠ l√Ω t·ªáp video v·ªõi OpenCV
                cap = cv2.VideoCapture(self.vid_file_name)
                if not cap.isOpened():
                    self.st.error("Kh√¥ng th·ªÉ m·ªü ngu·ªìn video.")
                    return

                while cap.isOpened():
                    success, frame = cap.read()
                    if not success:
                        self.st.warning("Kh√¥ng th·ªÉ ƒë·ªçc khung h√¨nh t·ª´ ngu·ªìn video.")
                        break

                    if self.enable_trk == "Yes":
                        results = self.model.track(
                            frame, conf=self.conf, iou=self.iou, classes=self.selected_ind, persist=True
                        )
                    else:
                        results = self.model(frame, conf=self.conf, iou=self.iou, classes=self.selected_ind)

                    annotated_frame = results[0].plot()

                    if stop_button:
                        cap.release()
                        self.st.stop()

                    self.org_frame.image(frame, channels="BGR")
                    self.ann_frame.image(annotated_frame, channels="BGR")

                cap.release()  # Gi·∫£i ph√≥ng t√†i nguy√™n video


if __name__ == "__main__":
    import sys  # Nh·∫≠p module sys ƒë·ªÉ truy c·∫≠p ƒë·ªëi s·ªë d√≤ng l·ªánh

    # Ki·ªÉm tra n·∫øu t√™n m√¥ h√¨nh ƒë∆∞·ª£c cung c·∫•p qua ƒë·ªëi s·ªë d√≤ng l·ªánh
    args = len(sys.argv)
    model = sys.argv[1] if args > 1 else None  # G√°n ƒë·ªëi s·ªë ƒë·∫ßu ti√™n l√†m t√™n m√¥ h√¨nh n·∫øu c√≥
    # T·∫°o th·ªÉ hi·ªán c·ªßa l·ªõp Inference v√† ch·∫°y suy lu·∫≠n
    Inference(model=model).inference()
